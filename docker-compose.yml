services:
  # --- Object Storage (S3-compatible) ---
  minio:
    image: minio/minio:latest
    container_name: clipfeed-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_USER:-clipfeed}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD:-changeme123}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 3

  # --- API Server ---
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: clipfeed-api
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_healthy
    environment:
      DB_PATH: /data/clipfeed.db
      L2R_MODEL_PATH: /data/l2r_model.json
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_USER:-clipfeed}
      MINIO_SECRET_KEY: ${MINIO_PASSWORD:-changeme123}
      MINIO_BUCKET: clips
      MINIO_USE_SSL: "false"
      JWT_SECRET: ${JWT_SECRET:-supersecretkey}
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
    volumes:
      - db_data:/data
    ports:
      - "8080:8080"

  # --- Ingestion Worker ---
  worker:
    build:
      context: ./ingestion
      dockerfile: Dockerfile
    container_name: clipfeed-worker
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_healthy
    environment:
      DB_PATH: /data/clipfeed.db
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: ${MINIO_USER:-clipfeed}
      MINIO_SECRET_KEY: ${MINIO_PASSWORD:-changeme123}
      MINIO_BUCKET: clips
      MINIO_USE_SSL: "false"
      WHISPER_MODEL: ${WHISPER_MODEL:-base}
      MAX_CONCURRENT_JOBS: ${MAX_WORKERS:-2}
      FFMPEG_THREADS: ${FFMPEG_THREADS:-2}
      WHISPER_THREADS: ${WHISPER_THREADS:-4}
      CLIP_TTL_DAYS: ${CLIP_TTL_DAYS:-30}
      JOB_STALE_MINUTES: ${JOB_STALE_MINUTES:-120}
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
    volumes:
      - db_data:/data
      - worker_tmp:/tmp/clipfeed
    deploy:
      resources:
        limits:
          cpus: "${WORKER_CPUS:-4}"

  # --- Score Updater ---
  score-updater:
    build:
      context: ./ingestion
      dockerfile: Dockerfile
    container_name: clipfeed-scorer
    restart: unless-stopped
    environment:
      DB_PATH: /data/clipfeed.db
      SCORE_UPDATE_INTERVAL: "${SCORE_UPDATE_INTERVAL:-900}"
    volumes:
      - db_data:/data
    command: ["python", "score_updater.py"]

  # --- Web Frontend ---
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: clipfeed-web
    restart: unless-stopped
    depends_on:
      - api
    ports:
      - "3000:3000"

  # --- Local LLM (Ollama) ---
  ollama:
    image: ollama/ollama:latest
    container_name: clipfeed-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        limits:
          cpus: "${OLLAMA_CPUS:-4}"

  # --- Content Scout Worker ---
  scout:
    build:
      context: .
      dockerfile: scout/Dockerfile
    container_name: clipfeed-scout
    restart: unless-stopped
    depends_on:
      - ollama
    environment:
      DB_PATH: /data/clipfeed.db
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      SCOUT_OLLAMA_AUTO_PULL: "${SCOUT_OLLAMA_AUTO_PULL:-1}"
      OLLAMA_PULL_TIMEOUT: "${OLLAMA_PULL_TIMEOUT:-900}"
      SCOUT_INTERVAL: "${SCOUT_INTERVAL:-21600}"
      LLM_THRESHOLD: "${LLM_THRESHOLD:-6}"
    volumes:
      - db_data:/data
    deploy:
      resources:
        limits:
          cpus: "${SCOUT_CPUS:-2}"

  # --- Reverse Proxy ---
  nginx:
    image: nginx:alpine
    container_name: clipfeed-proxy
    restart: unless-stopped
    depends_on:
      - api
      - web
      - minio
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro

volumes:
  minio_data:
  db_data:
  worker_tmp:
  ollama_data:
